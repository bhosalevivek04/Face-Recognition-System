import os
import io
import base64
import tempfile
from flask import Flask, request, jsonify
from gtts import gTTS
from face_module import extract_face_encoding, compare_face
from utils import speech_to_text, prepare_audio, load_face_db, save_face_db

app = Flask(__name__)

# Load our persistent face database on startup.
face_db = load_face_db()

@app.route('/register', methods=['POST'])
def register():
    """
    Registration endpoint.
    Expects form-data with:
      - 'image': image file (JPEG/PNG) containing the person's face.
      - 'audio': audio file (mp3, m4a, or wav) with the person speaking their name.
    The audio file is saved to a temporary file, converted to WAV if necessary, 
    then processed to extract the name via speech-to-text.
    The image is preprocessed and its face encoding is extracted and stored.
    Up to 5 samples per person are allowed.
    """
    if 'image' not in request.files or 'audio' not in request.files:
        return jsonify({"error": "Missing image or audio file."}), 400

    image_file = request.files['image']
    audio_file = request.files['audio']

    try:
        # Save the audio file with its original extension to a temporary file.
        audio_ext = os.path.splitext(audio_file.filename)[1]
        with tempfile.NamedTemporaryFile(suffix=audio_ext, delete=False) as temp_audio:
            audio_file.save(temp_audio.name)
            temp_audio_path = temp_audio.name

        # Convert the audio file if it's in mp3 or m4a format.
        converted_audio_path = prepare_audio(temp_audio_path)
        name = speech_to_text(converted_audio_path)
        
        # Clean up temporary audio files.
        os.remove(temp_audio_path)
        if converted_audio_path != temp_audio_path:
            os.remove(converted_audio_path)
        
        if not name:
            return jsonify({"error": "Speech recognition failed to obtain a name."}), 400

        # Save the image to a temporary file.
        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as temp_image:
            image_file.save(temp_image.name)
            temp_image_path = temp_image.name

        # Extract the face encoding from the image.
        encoding = extract_face_encoding(temp_image_path)
        os.remove(temp_image_path)

        if encoding is None:
            return jsonify({"error": "No face detected in the image."}), 400

        # Allow up to 5 samples per person.
        if name in face_db:
            if len(face_db[name]) >= 5:
                return jsonify({"error": f"Already registered maximum samples for '{name}'."}), 400
            face_db[name].append(encoding)
        else:
            face_db[name] = [encoding]

        # Save the updated database persistently.
        save_face_db(face_db)
        
        return jsonify({"message": f"Registered face for '{name}'. Total samples: {len(face_db[name])}."}), 200

    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/recognize', methods=['POST'])
def recognize():
    """
    Recognition endpoint:
      - Expects form-data with:
          'image': image file to be recognized.
      - Processes the image to extract the face encoding.
      - Compares the encoding with the stored face database.
      - Returns the recognized name (or "Unknown"), the matching distance,
        and a base64-encoded MP3 (generated by gTTS) of the recognized name.
    """
    if 'image' not in request.files:
        return jsonify({"error": "Missing image file."}), 400

    try:
        # Save the uploaded image to a temporary file.
        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as temp_image:
            request.files['image'].save(temp_image.name)
            temp_image_path = temp_image.name

        # Extract face encoding from the temporary image.
        encoding = extract_face_encoding(temp_image_path)
        if encoding is None:
            os.unlink(temp_image_path)
            return jsonify({"error": "No face detected in the image."}), 400

        # Compare the query encoding with the stored database.
        recognized_name, distance = compare_face(encoding, face_db, tolerance=0.5)
        os.unlink(temp_image_path)

        # Generate TTS audio for the recognized name.
        tts = gTTS(text=recognized_name, lang='en', slow=False)
        audio_io = io.BytesIO()
        tts.write_to_fp(audio_io)
        audio_io.seek(0)
        audio_base64 = base64.b64encode(audio_io.read()).decode('utf-8')

        return jsonify({
            "recognized_name": recognized_name,
            "distance": distance,
            "audio_mp3_base64": audio_base64
        }), 200

    except Exception as e:
        # Clean up temporary file if it exists.
        if 'temp_image_path' in locals() and os.path.exists(temp_image_path):
            os.unlink(temp_image_path)
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(host="0.0.0.0", port=5000, debug=True)